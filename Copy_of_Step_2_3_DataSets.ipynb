{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of Step_2_3_DataSets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimayyash/Python1/blob/master/Copy_of_Step_2_3_DataSets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6OzHNTtkkDh",
        "colab_type": "code",
        "outputId": "773784cb-2ece-4c57-ef7d-a3497853c31f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0rc3)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (46.1.3)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LGu1Y30iX3K",
        "colab_type": "code",
        "outputId": "4483f47b-9f37-4202-dee4-28718c3a98c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfMgLG8XzyFi",
        "colab_type": "code",
        "outputId": "22ce6e1c-0cfb-4c81-834d-7d1b7070fe94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import itertools \n",
        "import collections\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) # the simplest way to create a dataset is to create it from a python list:\n",
        "for element in dataset: \n",
        "  print(element)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMKDkbwtzyFw",
        "colab_type": "code",
        "outputId": "ec39bd3a-554c-48e7-c534-3542d6a94647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#dataset = tf.data.TextLineDataset([\"file1.txt\", \"file2.txt\"])  # To process lines from files, use tf.data.TextLineDataset0\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.map(lambda x: x*2) #  Once you have a dataset, you can apply transformations to prepare the data for your model:\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsG6sLe8zyF7",
        "colab_type": "code",
        "outputId": "8e5d9408-9100-46fa-ad3a-422cdc709c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Creates a dataset of a step-separated range of values\n",
        "list(dataset.range(5).as_numpy_iterator()) \n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUhg1S38zyGJ",
        "colab_type": "code",
        "outputId": "094521c3-8641-4810-90d3-dfef1858953a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(2, 5).as_numpy_iterator()) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6rOGVWbzyGT",
        "colab_type": "code",
        "outputId": "10bbaaa5-aba2-420d-d8cf-898ab417bd3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(1, 5, 2).as_numpy_iterator()) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGFteqpazyGf",
        "colab_type": "code",
        "outputId": "e4b557d2-239d-4477-ad8c-20c7e769de8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(1, 5, -2).as_numpy_iterator()) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbYu1EO-zyGt",
        "colab_type": "code",
        "outputId": "1d769506-eddc-4afe-fbb1-4a21136d05df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(5, 1, -2).as_numpy_iterator()) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR1_DHNnzyG5",
        "colab_type": "code",
        "outputId": "ce14b047-1ee2-46a9-af2c-cbd31191bd43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(5, 1).as_numpy_iterator()) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbnpLAgHzyHD",
        "colab_type": "code",
        "outputId": "056d85f8-e615-4b44-f759-81566a3b16c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Reduces the input dataset to a single element.\n",
        "tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, _: x + 1).numpy() \n",
        "#reduce(initial_state, reduce_func)\n",
        "#Reduces the input dataset to a single element.\n",
        "#The transformation calls reduce_func successively on every element \n",
        "#of the input dataset until the dataset is exhausted, \n",
        "#aggregating information in its internal state. \n",
        "#The initial_state argument is used for the initial state \n",
        "# and the final state is returned as the result."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T3YUFfmzyHJ",
        "colab_type": "code",
        "outputId": "1058590f-944e-4742-a874-d864ea97dde0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, y: x + y).numpy()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFKN4_8ozyHR",
        "colab_type": "code",
        "outputId": "4bbb1fc7-f701-4c7f-f248-4a4de1fb668d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.repeat(3) \n",
        "list(dataset.as_numpy_iterator()) \n",
        "#Repeats this dataset so each original value is seen count times."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 1, 2, 3, 1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV5_YKF1zyHV",
        "colab_type": "code",
        "outputId": "34e916bc-0b9e-42f6-e52e-af398ea2aee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ] \n",
        "dataset = dataset.map(lambda x: x + 1) \n",
        "#  Maps map_func across the elements of this dataset.\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4, 5, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbIzPUlFzyHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.range(5) \n",
        "# `map_func` takes a single argument of type `tf.Tensor` with the same \n",
        "# shape and dtype. \n",
        "result = dataset.map(lambda x: x + 1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VftZ3OsCzyHi",
        "colab_type": "code",
        "outputId": "aa80c328-41b6-4c3f-8581-073215954c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Each element is a tuple containing two `tf.Tensor` objects. \n",
        "elements = [(1, \"foo\"), (2, \"bar\"), (3, \"baz)\")] \n",
        "dataset = tf.data.Dataset.from_generator( \n",
        "    lambda: elements, (tf.int32, tf.string)) \n",
        "# `map_func` takes two arguments of type `tf.Tensor`. This function \n",
        "# projects out just the first component. \n",
        "result = dataset.map(lambda x_int, y_str: x_int) \n",
        "list(result.as_numpy_iterator()) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t5vIHVXzyHn",
        "colab_type": "code",
        "outputId": "0fc6d916-3afa-4368-9c66-4ec585e6a634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import itertools \n",
        "import collections\n",
        "a = 1 # Integer element \n",
        "b = 2.0 # Float element \n",
        "c = (1, 2) # Tuple element with 2 components \n",
        "d = {\"a\": (2, 2), \"b\": 3} # Dict element with 3 components \n",
        "Point = collections.namedtuple(\"Point\", [\"x\", \"y\"]) # doctest: +SKIP Elements can be nested structures of tuples, named tuples, and dictionaries.\n",
        "e = Point(1, 2) # Named tuple # doctest: +SKIP \n",
        "f = tf.data.Dataset.range(10) # Dataset element \n",
        "e                  # readable __repr__ with a name=value style"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Point(x=1, y=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbhhElNRzyHu",
        "colab_type": "code",
        "outputId": "7268b36d-8423-4b6e-c593-3ba44c8f43de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "e[0] + e[1] # indexable like the plain tuple (1, 2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrNyJS1bzyH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = e                # unpack like a regular tuple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFvKTEPjzyH-",
        "colab_type": "code",
        "outputId": "568a955e-ee58-41c2-99dd-9343e88f6b52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x, y"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nezjMwkPzyIC",
        "colab_type": "code",
        "outputId": "96733d1b-f188-4a17-faca-e83fa2e744b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "e.x + e.y               # fields also accessible by name"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIR0pqMqzyII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]).element_spec  # element_spec: The type specification of an element of this dataset."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isc_TOOezyIM",
        "colab_type": "code",
        "outputId": "fe137b44-2ec4-44b5-f988-058e0ce22c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(100) \n",
        "def dataset_fn(ds): # transformation_func: A function that takes one Dataset argument and returns a Dataset.\n",
        "  return ds.filter(lambda x: x < 5) \n",
        "dataset = dataset.apply(dataset_fn) # apply enables chaining of custom Dataset transformations, which are represented as functions that take one Dataset argument and return a transformed Dataset.\n",
        "list(dataset.as_numpy_iterator()) # Returns an iterator which converts all elements of the dataset to numpy."
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoJRgCFSzyIU",
        "colab_type": "code",
        "outputId": "bf8c9f1b-5038-49c8-8ef2-e9d989e53b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bztE1DAOzyIZ",
        "colab_type": "code",
        "outputId": "6ebf0f6e-406d-4350-ff93-ba0ef365f3f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "print(list(dataset.as_numpy_iterator())) "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6ZUx9DDzyIe",
        "colab_type": "code",
        "outputId": "7fec18db-d555-4d7b-fa45-a20cd178ad8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]), \n",
        "                                              'b': [5, 6]}) \n",
        "list(dataset.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5}, # as_numpy_iterator() will preserve the nested structure of dataset elements.\n",
        "                                      {'a': (2, 4), 'b': 6}] "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaiusP8jzyIl",
        "colab_type": "code",
        "outputId": "ab734aa9-969e-452b-cb8b-0964a7b1b2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(8)  \n",
        "dataset = dataset.batch(3) # Combines consecutive elements of this dataset into batches.\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtqBv9gXzyIr",
        "colab_type": "code",
        "outputId": "698f4261-b7e9-47f1-83b3-cc7fdb1afd4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(8) \n",
        "dataset = dataset.batch(3, drop_remainder=True) #  If your program depends on the batches having the same outer dimension, you should set the drop_remainder argument to True to prevent the smaller batch from being produced.\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioklpGSKzyIx",
        "colab_type": "code",
        "outputId": "c792a5cf-6fa9-4bf2-b073-cc0ddefeef75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(5) \n",
        "dataset = dataset.map(lambda x: x**2) \n",
        "dataset = dataset.cache() #Caches the elements in this dataset.\n",
        "# The first time reading through the data will generate the data using \n",
        "# `range` and `map`. \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 4, 9, 16]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XtuMhhszyI4",
        "colab_type": "code",
        "outputId": "9a0069cf-1c27-463c-c412-4139797a3c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Subsequent iterations read from the cache. \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 4, 9, 16]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GOPLCdnzyI8",
        "colab_type": "code",
        "outputId": "befe9d12-1f4c-4113-b72c-397bf0d5b500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ] \n",
        "b = tf.data.Dataset.range(4, 8)  # ==> [ 4, 5, 6, 7 ] \n",
        "ds = a.concatenate(b) # Creates a Dataset by concatenating the given dataset with this dataset.\n",
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmTwIWfHzyJA",
        "colab_type": "code",
        "outputId": "0877f0f5-fc4f-4c3c-9ccc-03fa5f11c9c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Slicing a 1D tensor produces scalar tensor elements. \n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVT4COLwzyJJ",
        "colab_type": "code",
        "outputId": "c30bcab8-7a17-4ca7-9fbd-cd51021886d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Slicing a 1D tensor produces scalar tensor elements. \n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QZGsfQJzyJP",
        "colab_type": "code",
        "outputId": "b3b07d37-9945-45c3-e288-635868fe6018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Slicing a tuple of 1D tensors produces tuple elements containing \n",
        "# scalar tensors. \n",
        "dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6])) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 3, 5), (2, 4, 6)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzTLa731zyJT",
        "colab_type": "code",
        "outputId": "8ced2737-4fca-44a9-a38f-18bd0f692970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Dictionary structure is also preserved. \n",
        "dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]}) \n",
        "list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3}, \n",
        "                                      {'a': 2, 'b': 4}]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtKU5zUJzyJg",
        "colab_type": "code",
        "outputId": "c65026c8-5e99-4a93-f004-46ee35fe84cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Two tensors can be combined into one Dataset object. \n",
        "features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor \n",
        "labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor \n",
        "dataset = dataset.from_tensor_slices((features, labels)) \n",
        "# Both the features and the labels tensors can be converted \n",
        "# to a Dataset object separately and combined after. \n",
        "features_dataset = dataset.from_tensor_slices(features) \n",
        "labels_dataset = dataset.from_tensor_slices(labels) \n",
        "dataset = dataset.zip((features_dataset, labels_dataset)) \n",
        "# A batched feature and label set can be converted to a Dataset \n",
        "# in similar fashion. \n",
        "batched_features = tf.constant([[[1, 3], [2, 3]], \n",
        "                                [[2, 1], [1, 2]], \n",
        "                                [[3, 3], [3, 2]]], shape=(3, 2, 2)) \n",
        "batched_labels = tf.constant([['A', 'A'], \n",
        "                              ['B', 'B'], \n",
        "                              ['A', 'B']], shape=(3, 2, 1)) \n",
        "dataset = dataset.from_tensor_slices((batched_features, batched_labels)) \n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element) "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([[1, 3],\n",
            "       [2, 3]], dtype=int32), array([[b'A'],\n",
            "       [b'A']], dtype=object))\n",
            "(array([[2, 1],\n",
            "       [1, 2]], dtype=int32), array([[b'B'],\n",
            "       [b'B']], dtype=object))\n",
            "(array([[3, 3],\n",
            "       [3, 2]], dtype=int32), array([[b'A'],\n",
            "       [b'B']], dtype=object))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oxILufvzyJj",
        "colab_type": "code",
        "outputId": "61fbe6bd-6ba0-440c-936e-dce3da87aa48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.enumerate(start=5) #Enumerates the elements of this dataset.\n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 1)\n",
            "(6, 2)\n",
            "(7, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0e4NzCSzyJo",
        "colab_type": "code",
        "outputId": "b5b7f9d7-56f0-4abb-a35b-8b8156d98782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# The nested structure of the input dataset determines the structure of \n",
        "# elements in the resulting dataset. \n",
        "dataset = tf.data.Dataset.from_tensor_slices([(7, 8), (9, 10)]) \n",
        "dataset = dataset.enumerate() \n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element) "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, array([7, 8], dtype=int32))\n",
            "(1, array([ 9, 10], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKFU1g0izyJw",
        "colab_type": "code",
        "outputId": "d76c933a-4e91-4417-9d25-69efff1b537b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.filter(lambda x: x < 3) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl2FTn8rzyJ_",
        "colab_type": "code",
        "outputId": "bcc252d0-5970-4d07-c3cd-dc52861d8821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# `tf.math.equal(x, y)` is required for equality comparison \n",
        "def filter_fn(x): \n",
        "  return tf.math.equal(x, 1) \n",
        "dataset = dataset.filter(filter_fn) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0y-_EExzyKC",
        "colab_type": "code",
        "outputId": "5e1a76cd-2967-4d1f-852f-f1bda09ad9e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = dataset.from_tensor_slices([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) \n",
        "dataset = dataset.flat_map(lambda x: dataset.from_tensor_slices(x)) # Use flat_map if you want to make sure that the order of your dataset stays the same. \n",
        "#For example, to flatten a dataset of batches into a dataset of their elements\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bijMSAjxzyKH",
        "colab_type": "code",
        "outputId": "a53d4574-9210-4e63-f9b4-0f74fec1c2cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def gen(): \n",
        "  for i in itertools.count(1): \n",
        "    yield (i, [1] * i) \n",
        "dataset = tf.data.Dataset.from_generator(gen,  #Creates a Dataset whose elements are generated by generator.\n",
        "     (tf.int64, tf.int64), \n",
        "     (tf.TensorShape([]), tf.TensorShape([None]))) \n",
        "list(dataset.take(3).as_numpy_iterator())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, array([1])), (2, array([1, 1])), (3, array([1, 1, 1]))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alq0SFvIzyKN",
        "colab_type": "code",
        "outputId": "c346bb60-4926-4ae1-bcbc-5ff91ff474b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensors([1, 2, 3]) # Creates a Dataset with a single element, comprising the given tensors.\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2, 3], dtype=int32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QGg5cIfzyKT",
        "colab_type": "code",
        "outputId": "c04b50c6-7a11-4082-f051-f03fbf663575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensors(([1, 2, 3], 'A')) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([1, 2, 3], dtype=int32), b'A')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy3Og8tFzyKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess 4 files concurrently, and interleave blocks of 16 records \n",
        "# from each file. \n",
        "filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\", \n",
        "             \"/var/data/file3.txt\", \"/var/data/file4.txt\"] \n",
        "dataset = tf.data.Dataset.from_tensor_slices(filenames) \n",
        "def parse_fn(filename): \n",
        "  return tf.data.Dataset.range(10) \n",
        "dataset = dataset.interleave(lambda x: \n",
        "    tf.data.TextLineDataset(x).map(parse_fn, num_parallel_calls=1), \n",
        "    cycle_length=4, block_length=16) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv5DZ7qszyKk",
        "colab_type": "code",
        "outputId": "a2c04d8a-6af1-4e0e-8830-1e5716207ce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "dataset = dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ] \n",
        "# NOTE: New lines indicate \"block\" boundaries. \n",
        "dataset = dataset.interleave( \n",
        "    lambda x: dataset.from_tensors(x).repeat(6), \n",
        "    cycle_length=2, block_length=4) \n",
        "list(dataset.as_numpy_iterator()) \n",
        "#The cycle_length and block_length arguments control the order in which elements are produced. \n",
        "#cycle_length controls the number of input elements that are processed concurrently.\n",
        "#cycle_length input elements, open iterators on the returned Dataset objects, \n",
        "# and cycle through them producing block_length consecutive elements from each iterator, "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bvgKAHdzyKq",
        "colab_type": "code",
        "outputId": "cdbdaa7d-cfdf-4660-f03e-aa61cba726d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "elements = [[1, 2], \n",
        "            [3, 4, 5], \n",
        "            [6, 7], \n",
        "            [8]] \n",
        "A = tf.data.Dataset.from_generator(lambda: iter(elements), tf.int32) \n",
        "# Pad to the smallest per-batch size that fits all elements. \n",
        "B = A.padded_batch(2, padded_shapes=[None]) \n",
        "for element in B.as_numpy_iterator(): \n",
        "  print(element) \n",
        "#Combines consecutive elements of this dataset into padded batches.\n",
        "#This transformation combines multiple consecutive elements of the input dataset into a single element."
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 0]\n",
            " [3 4 5]]\n",
            "[[6 7]\n",
            " [8 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMQojFYZzyKz",
        "colab_type": "code",
        "outputId": "736c4702-200e-44bb-f11f-0cad375b071a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(3) \n",
        "dataset = dataset.prefetch(2) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgwxDxGwzyK-",
        "colab_type": "code",
        "outputId": "8b088379-8aa3-4b29-9806-0fac9f272151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "a = tf.add(3, 5)\n",
        "print(a)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(8, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gsFWi9kzyLF",
        "colab_type": "code",
        "outputId": "28a8f01f-7888-4f89-9579-1b17e26200f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "a = tf.constant([[3, 5], [4, 8]])\n",
        "b = tf.constant([[1, 6], [2, 9]])\n",
        "tf.math.add_n([a, b, a])  # [[7, 16], [10, 25]]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 7, 16],\n",
              "       [10, 25]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcGaF2EPzyLJ",
        "colab_type": "code",
        "outputId": "328a9a7a-0bb2-4dcf-e323-9a4d4c58c603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Launch the graph in a session.\n",
        "with tf.compat.v1.Session() as ses:\n",
        "     # Build a graph.\n",
        "     a = tf.constant(5.0)\n",
        "     b = tf.constant(6.0)\n",
        "     c = tf.add(a, b)\n",
        "     # Evaluate the tensor `c`.\n",
        "     print(ses.run(c))\n",
        "# Using the `close()` method.\n",
        "ses.close()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmRvvl9fzyLT",
        "colab_type": "code",
        "outputId": "9941857e-d77d-4690-81c8-609678286c57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "x = 2\n",
        "y = 3\n",
        "op1 = tf.add(x, y)\n",
        "op2 = tf.multiply(x, y)\n",
        "op3 = tf.pow(op2, op1)\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    op3 = sess.run(op3)\n",
        "print(op3)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-17e52c60323e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mop3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mop3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1166\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \"\"\"\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    303\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 305\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    306\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3511\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3512\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3514\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3588\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m       \u001b[0;31m# Actually obj is just the object it's referring to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1116\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m     raise AttributeError(\n\u001b[0;32m-> 1118\u001b[0;31m         \"Tensor.graph is meaningless when eager execution is enabled.\")\n\u001b[0m\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Tensor.graph is meaningless when eager execution is enabled."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm6tsdbhzyLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Launch the graph in a session.\n",
        "with tf.compat.v1.Session() as ses:\n",
        "     # Build a graph.\n",
        "      x = 2\n",
        "      y = 3\n",
        "      add_op = tf.add(x, y)\n",
        "      mul_op = tf.multiply(x, y)\n",
        "      useless = tf.multiply(x, add_op)\n",
        "      pow_op = tf.pow(add_op, mul_op)\n",
        "      # Evaluate the tensor `c`.\n",
        "      print(ses.run(pow_op))\n",
        "# Using the `close()` method.\n",
        "ses.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0XxLTMPzyLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates a graph.\n",
        "physical_devices = tf.config.list_physical_devices('GPU') \n",
        "try: \n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
        "except: \n",
        "  # Invalid device or cannot modify virtual devices once initialized. \n",
        "  pass \n",
        "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='a')\n",
        "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='b')\n",
        "  c = tf.multiply(a, b)\n",
        "# Creates a session with log_device_placement set to True.\n",
        "#sess = tf.compat.v1.Session(config=tf.config.experimental(log_device_placement=True))\n",
        "# Runs the op.\n",
        "print(c)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTWoWwNhzyLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}